{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[10323]: Class AVFFrameReceiver is implemented in both /usr/local/Cellar/ffmpeg/6.0_1/lib/libavdevice.60.1.100.dylib (0x11866a378) and /Users/macos/miniconda3/envs/zaic2023/lib/python3.10/site-packages/av/.dylibs/libavdevice.59.7.100.dylib (0x11c8c0118). One of the two will be used. Which one is undefined.\n",
      "objc[10323]: Class AVFAudioReceiver is implemented in both /usr/local/Cellar/ffmpeg/6.0_1/lib/libavdevice.60.1.100.dylib (0x11866a3c8) and /Users/macos/miniconda3/envs/zaic2023/lib/python3.10/site-packages/av/.dylibs/libavdevice.59.7.100.dylib (0x11c8c0168). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import typing as tp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from audiocraft.models import MusicGen, MultiBandDiffusion\n",
    "from audiocraft.data.audio_utils import normalize_audio\n",
    "\n",
    "from config import CFG\n",
    "from utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macos/miniconda3/envs/zaic2023/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MusicGen.get_pretrained(CFG.AUDIO_CRAFT_MODEL, device=CFG.DEVICE)\n",
    "\n",
    "model.lm.load_state_dict(\n",
    "    torch.load(\n",
    "        \"model/musicgen_4000.0.pt\",\n",
    "        map_location=CFG.DEVICE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 10\n",
    "JSON_PATH = \"private/private.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inference = pd.read_json(JSON_PATH, orient=\"index\").reset_index()\n",
    "df_inference.columns = [\"filename\", \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, descriptions):\n",
    "    attributes, prompt_tokens = model._prepare_tokens_and_attributes(descriptions, None)\n",
    "    model.generation_params = {\n",
    "        'max_gen_len': int(DURATION/2 * model.frame_rate),\n",
    "        'use_sampling': True,\n",
    "        'temp': 1.0,\n",
    "        'top_k': 250,\n",
    "        'top_p': 0.5,\n",
    "        'cfg_coef': 3.0,\n",
    "        'two_step_cfg': False,\n",
    "    }\n",
    "    total = []\n",
    "    for _ in range(1):\n",
    "        with model.autocast:\n",
    "            gen_tokens = model.lm.generate(\n",
    "                prompt_tokens, attributes, callback=None, **model.generation_params)\n",
    "            total.append(\n",
    "                gen_tokens[..., prompt_tokens.shape[-1] if prompt_tokens is not None else 0:])\n",
    "            prompt_tokens = gen_tokens[..., -gen_tokens.shape[-1] // 2:]\n",
    "    gen_tokens = torch.cat(total, -1)\n",
    "\n",
    "    assert gen_tokens.dim() == 3\n",
    "    with torch.no_grad():\n",
    "        gen_audio = model.compression_model.decode(gen_tokens, None)\n",
    "\n",
    "    for idx, one_wav in enumerate(gen_audio):\n",
    "        assert one_wav.dtype.is_floating_point, \"wav is not floating point\"\n",
    "        if one_wav.dim() == 1:\n",
    "            one_wav = one_wav[None]\n",
    "        elif one_wav.dim() > 2:\n",
    "            raise ValueError(\"Input wav should be at most 2 dimension.\")\n",
    "        assert one_wav.isfinite().all()\n",
    "    return one_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                    | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch                 filename                                        description\n",
      "0  1699168496.395952.mp3  The recording features a widely spread electri...\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                        | 1/1000 [01:13<20:15:47, 73.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch                 filename                                        description\n",
      "1  1699168495.217152.mp3  The recording features a cover of a rock song ...\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                        | 2/1000 [02:28<20:35:14, 74.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch                  filename                                        description\n",
      "2  1699168495.1176987.mp3  The recording features an arpeggiated acoustic...\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                                        | 3/1000 [03:31<19:07:52, 69.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch                  filename                                        description\n",
      "3  1699168498.4178677.mp3  The recording features a cover of a rock song ...\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                        | 4/1000 [04:38<18:55:20, 68.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch                  filename                                        description\n",
      "4  1699168495.6089337.mp3  The recording features an arpeggiated acoustic...\n",
      "---------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                        | 5/1000 [05:49<19:09:44, 69.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch                 filename                                        description\n",
      "5  1699168495.505732.mp3  The recording features a cover of a rock song ...\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "all_predicted_time = []\n",
    "output_path1 = \"results/jupyter_submission1\"\n",
    "\n",
    "if not os.path.exists(output_path1):\n",
    "    os.makedirs(output_path1)\n",
    "\n",
    "for idx, batch in tqdm(df_inference.groupby(np.arange(len(df_inference)) // BATCH_SIZE)):\n",
    "    print('Processing batch', batch)\n",
    "    print(\"---------------------\")\n",
    "    filenames = batch[\"filename\"].tolist()\n",
    "    descriptions = batch[\"description\"].tolist()\n",
    "    t1 = time.time()\n",
    "    # ***************Start model prediction******************\n",
    "    one_wav = generate(model, descriptions)\n",
    "    one_wav = normalize_audio(\n",
    "        wav=one_wav.cpu(),\n",
    "        strategy=CFG.STRATEGY,\n",
    "        peak_clip_headroom_db=CFG.PEAK,\n",
    "        loudness_compressor=CFG.LOUDNESS_COMPRESSOR,\n",
    "        sample_rate=CFG.SAMPLE_RATE,\n",
    "    )\n",
    "    path_submission1 = os.path.join(output_path1, filenames[0])\n",
    "    torchaudio.save(path_submission1, one_wav, CFG.SAMPLE_RATE)\n",
    "    # ***************End model prediction******************\n",
    "    t2 = time.time()\n",
    "    predicted_time = t2 - t1\n",
    "    all_predicted_time.append((filenames, predicted_time))\n",
    "\n",
    "df = pd.DataFrame(all_predicted_time, columns=[\"fname\", \"time\"])\n",
    "df.to_csv(\"results/time_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_predicted_time = []\n",
    "output_path2 = \"results/jupyter_submission2\"\n",
    "\n",
    "if not os.path.exists(output_path2):\n",
    "    os.makedirs(output_path2)\n",
    "\n",
    "for idx, batch in tqdm(df_inference.groupby(np.arange(len(df_inference)) // BATCH_SIZE)):\n",
    "    print('Processing batch', batch)\n",
    "    print(\"---------------------\")\n",
    "    filenames = batch[\"filename\"].tolist()\n",
    "    descriptions = batch[\"description\"].tolist()\n",
    "    t1 = time.time()\n",
    "    # ***************Start model prediction******************\n",
    "    forward = generate(model, descriptions)\n",
    "    one_wav = normalize_audio(\n",
    "        wav=one_wav.cpu(),\n",
    "        strategy=CFG.STRATEGY,\n",
    "        peak_clip_headroom_db=CFG.PEAK,\n",
    "        loudness_compressor=CFG.LOUDNESS_COMPRESSOR,\n",
    "        sample_rate=CFG.SAMPLE_RATE,\n",
    "    )\n",
    "    path_submission2 = os.path.join(output_path2, filenames[0])\n",
    "    torchaudio.save(path_submission2, forward, CFG.SAMPLE_RATE)\n",
    "    # ***************End model prediction******************\n",
    "    t2 = time.time()\n",
    "    predicted_time = t2 - t1\n",
    "    all_predicted_time.append((filenames, predicted_time))\n",
    "\n",
    "df = pd.DataFrame(all_predicted_time, columns=[\"fname\", \"time\"])\n",
    "df.to_csv(\"results/time_submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
